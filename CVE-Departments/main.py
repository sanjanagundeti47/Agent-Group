import math
import threading
from concurrent.futures.thread import ThreadPoolExecutor

import requests
import time
import os
from dotenv import dotenv_values
import pandas as pd

config = dotenv_values(".env")


class Tenable:

    def __init__(self):
        self.config = config
        self.headers = {
            "X-ApiKeys": f"accessKey={self.config.get('access')};"
                         f"secretKey={self.config.get('secret')}"
        }
        self.url = self.config.get('url')
        self.cve = ""
        self.file_name = ""
        self.request = 1
        self.drop_tags_keys = ["product", "value_uuid", "category_name", "container_uuid", "created_at",
                               "source"]
        self.drop_cats_keys = ["created_at", "created_by", "updated_at", "updated_by", "product", "description",
                               "reserved", "value_count"]
        self.calLock = threading.Lock()
        self.tags = []
        self.cats = pd.DataFrame()

    def main(self):
        try:
            self.__readCVEfromFile()
            self.__processCSVFile()
        except Exception as e:
            print("Unable to process: ", e)

    def __readCVEfromFile(self) -> None:
        try:
            cves = open('list_of_cve.txt', 'r').readlines()
            self.getFileOfCVE(cves)
        except Exception as e:
            print("Error occurred while reading CVE(s) from file: ", e)

    def getFileOfCVE(self, cves: list) -> None:
        try:
            for cve in cves:
                self.__exportRequest(cve.strip('\n'))
                  # Remove this line while running for multiple CVEs
        except Exception as e:
            print("Error occurred while requesting export for CVE: ", e)

    def __exportRequest(self, cve: str) -> None:
        try:
            url = self.url + "workbenches/export?format=csv&report=vulnerabilities&" \
                             "chapter=vuln_by_asset&filter.0.filter=plugin.attributes.cve.raw&" \
                             f"filter.0.quality=match&filter.0.value={cve}"
            res = requests.get(url, headers=self.headers)
            self.cve = cve
            print(f'Getting data for CVE: {cve}')
            self.__checkProgress(res.json().get('file'))
        except Exception as e:
            print("Error occurred while sending export request: ", e)

    def __checkProgress(self, file_id: int) -> None:
        try:
            url = self.url + f"workbenches/export/{file_id}/status"
            self.headers["Accept"] = "application/json"
            res = requests.get(url, headers=self.headers)
            time.sleep(5)
            while not res.json().get('status') == 'ready':
                print(f"File is being processed: {res.json().get('progress')}/{res.json().get('progress_total')}")
                res = requests.get(url, headers=self.headers)
                time.sleep(5)
            self.__downloadFile(file_id)
        except Exception as e:
            print("Error occurred while checking progress of file: ", e)

    def __downloadFile(self, file_id: int) -> None:
        try:
            url = self.url + f"workbenches/export/{file_id}/download"
            self.headers["Accept"] = "application/octet-stream"
            res = requests.get(url, headers=self.headers)
            if not os.path.isdir('data'):
                os.mkdir('data')
            if not os.path.isdir(f'data/{self.cve}'):
                os.mkdir(f'data/{self.cve}')
            self.file_name = f'data/{self.cve}/{self.cve}.csv'
            with open(self.file_name, 'wb') as f:
                f.write(res.content)
            print(f"File downloaded successfully at {self.file_name}")
        except Exception as e:
            print("Error occurred while downloading the file: ", e)

    def __processCSVFile(self) -> None:
        df = pd.read_csv(self.file_name)
        try:
            assets = df["Asset UUID"].to_list()
            number_of_thread_workers = 150
            number_of_batches = math.ceil(len(assets) / number_of_thread_workers)

            import numpy as np
            uid_batches_list = np.array_split(assets, number_of_batches)
            print('Total uids batch: {}'.format(len(uid_batches_list)))
            batch_count = 1
            for batch_list in uid_batches_list:
                with ThreadPoolExecutor(max_workers=number_of_thread_workers) as executor:
                    for uid in batch_list:
                        executor.submit(self.__getTagsByAsset, uid)
                sleep_time = 3
                print('Batch of uids: {}, Going to sleep for {} seconds'.format(
                    batch_count, sleep_time))
                time.sleep(sleep_time)
                print('######## Batch of uids Done - {}'.format(batch_count))
                batch_count = batch_count + 1

        except Exception as e:
            print("Error occurred while reading CSV file: ", e)

        finally:
            tags_df = pd.DataFrame(self.tags)
            self.loadCategories()
            dept_df = pd.DataFrame(self.cats)
            tags_df.rename(columns={'asset_uuid': 'Asset UUID', 'value': 'Tag'}, inplace=True)
            tags_df.to_csv(f'data/{self.cve}/{self.cve}_Tags.csv', index=False)

            dept_df.rename(columns={'uuid': 'category_uuid', 'name': 'Department'}, inplace=True)
            dept_df.to_csv(f'data/{self.cve}/{self.cve}_Categories.csv', index=False)

            inner_join_df = tags_df.merge(dept_df, how="left", on="category_uuid")
            inner_join_df = inner_join_df.drop(["category_uuid"], axis=1)
            inner_join_df = inner_join_df.drop(["created_by"], axis=1)
            inner_join_df.to_csv(f'data/{self.cve}/{self.cve}_Temp.csv', index=False)

            result = df.merge(inner_join_df, how="left", on="Asset UUID")
            result.to_csv(f'data/{self.cve}/{self.cve}_Report.csv', index=False)
            print("Process completed!")

    def __getTagsByAsset(self, asset_id: str) -> None:
        try:
            asset_tags_endpoint = self.url + f"tags/assets/{asset_id}/assignments"
            # self.checkRequestCount()
            res = requests.get(asset_tags_endpoint, headers=self.headers)
            if res.status_code == 200:
                res = res.json()
                if res["tags"]:
                    [res['tags'][i].pop(key) for i in range(len(res['tags'])) for key in self.drop_tags_keys]
                    self.tags.extend(res["tags"])
        except Exception as e:
            print("Error occurred while getting tags by asset: ", e)

    def loadCategories(self):
        res = requests.get(self.url + f"tags/categories", headers=self.headers)
        res = res.json()
        self.cats = pd.DataFrame(res["categories"])
        self.cats = self.cats.drop(self.drop_cats_keys, axis=1)

    def checkRequestCount(self):
        if self.request % 10 == 0:
            time.sleep(5)
            print("Too many requests! Taking break of 5 seconds.")
        else:
            self.request += 1


if __name__ == "__main__":
    t = Tenable()
    t.main()
